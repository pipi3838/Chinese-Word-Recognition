{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "from  matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "path = '/nfs/nas-5.1/wbcheng/Chinese_Word_Recognition/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for file in tqdm(glob(os.path.join(path, 'Modified', '*.jpg'))):\n",
    "    img_name = file.split('/')[-1]\n",
    "    store[img_name[-5]].append(img_name.split('_')[0])\n",
    "    cnt += 1\n",
    "#     im = Image.open(file).convert(\"RGB\")\n",
    "    im = cv2.imread(file, 0)\t# load image as bgr\n",
    "#     im = im[:,:,::-1] \t# transform image to rgb\n",
    "    \n",
    "    _, thre_img = cv2.threshold(im, 0, 255, cv2.THRESH_OTSU)\n",
    "    total += 1\n",
    "#     plt.imshow(thre_img, 'gray')\n",
    "#     plt.show()\n",
    "    cv2.imwrite(os.path.join(path, 'Modified_Thres', img_name), thre_img)\n",
    "print('Finish {} image'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 25009/250713 [03:25<40:17, 93.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 46909/250713 [14:27<3:26:26, 16.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 57701/250713 [25:51<3:31:35, 15.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 84548/250713 [1:02:02<4:10:55, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 97241/250713 [1:22:46<4:44:39,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 101026/250713 [1:29:26<4:39:36,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 105788/250713 [1:38:05<4:47:06,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 106332/250713 [1:39:06<4:51:37,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 123624/250713 [2:13:31<4:21:38,  8.10it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 149650/250713 [3:13:13<4:04:03,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 151037/250713 [3:16:39<4:04:56,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 178199/250713 [4:29:34<3:21:02,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 178254/250713 [4:29:44<3:25:48,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 200014/250713 [5:35:41<2:38:30,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 203270/250713 [5:46:08<2:29:57,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 205382/250713 [5:53:01<2:26:55,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 209763/250713 [6:07:29<2:14:52,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 234071/250713 [7:32:11<1:00:08,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 249325/250713 [8:29:31<05:21,  4.32it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250713/250713 [8:34:52<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 250712 img found 250693 bounding box\t 19 not found\t1 null images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./word2label.json', 'r', encoding='utf-8') as f:\n",
    "    word2label = json.load(f)\n",
    "\n",
    "found = 0\n",
    "not_found = 0\n",
    "null_cnt = 0\n",
    "total = 0\n",
    "\n",
    "for file in tqdm(glob(os.path.join(path, 'Pretrain_Common', '*'))):\n",
    "    img_name = file.split('/')[-1]\n",
    "    label = img_name.split('_')[0]\n",
    "    im = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\t# load image as bgr\n",
    "    \n",
    "    if im is None:\n",
    "        null_cnt += 1\n",
    "        continue\n",
    "        \n",
    "    total += 1\n",
    "    \n",
    "    _, thre_img = cv2.threshold(im, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    thre_img = cv2.fastNlMeansDenoising(thre_img, h=13, searchWindowSize=7)\n",
    "#         kernel = np.ones((3,3), np.uint8)\n",
    "#         thre_img = cv2.erode(thre_img, kernel, iterations = 1)\n",
    "\n",
    "    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "    dilate = cv2.dilate(thre_img, rect_kernel, iterations = 1)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    if len(contours) == 0:\n",
    "        bound = cv2.resize(im, (50,50))\n",
    "        print('not found')\n",
    "        not_found += 1\n",
    "    else:\n",
    "        max_area = -1\n",
    "        bx, by, bw, bh = None, None, None, None\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            if w * h > max_area:\n",
    "                bx, by, bw, bh = x, y, w, h\n",
    "                max_area = w * h\n",
    "            # Drawing a rectangle on copied image\n",
    "        bound = cv2.resize(im[by:by+bh, bx:bx+bw], (50, 50))\n",
    "        rect = cv2.rectangle(im, (bx, by), (bx + bw, by + bh), (0, 0, 255), 1)\n",
    "        found += 1\n",
    "\n",
    "    cv2.imwrite(os.path.join(path, 'Pretrain_Common_Modified', img_name), bound)\n",
    "\n",
    "print('Total {} img found {} bounding box\\t {} not found\\t{} null images'.format(total, found, not_found, null_cnt))\n",
    "\n",
    "#         imgs = [im, thre_img, dilate, bound]\n",
    "#         titles = ['ori', 'thre_img', 'dilate', 'bounding']\n",
    "#         fig, axs = plt.subplots(nrows=1, ncols=4)\n",
    "#         for i, ax in enumerate(axs.flatten()):\n",
    "#             plt.sca(ax)\n",
    "#             plt.imshow(imgs[i], 'gray', vmin=0, vmax=255)\n",
    "#             plt.title('Image: {}'.format(titles[i]))\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob(os.path.join(path, 'Modified_Thres', '*')):\n",
    "    img_name = file.split('/')[-1]\n",
    "    im = cv2.imread(file, 1)\t# load image as bgr\n",
    "    im = im[:,:,::-1]\n",
    "    print(img_name)\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    \n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob(os.path.join(path, 'Pretrain_Common_Modified', '*')):\n",
    "    img_name = file.split('/')[-1]\n",
    "    label = img_name.split('_')[0]\n",
    "    im = cv2.imread(file, 1)\t# load image as bgr\n",
    "    im = im[:,:,::-1]\n",
    "    print(img_name)\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    \n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = defaultdict(list)\n",
    "found = 0\n",
    "not_found = 0\n",
    "null_cnt = 0\n",
    "total = 0\n",
    "\n",
    "for file in tqdm(glob(os.path.join(path, 'Origin', '*.jpg'))):\n",
    "    img_name = file.split('/')[-1]\n",
    "    store[img_name[-5]].append(img_name.split('_')[0])\n",
    "    ori_img = cv2.imread(file, 1)\n",
    "    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    total += 1\n",
    "    if ori_img is None:\n",
    "#         print('NULL image ', img_name)\n",
    "        null_cnt += 1\n",
    "        continue\n",
    "\n",
    "    _, thre_img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "#     _, im = cv2.threshold(im, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "#     im = cv2.adaptiveThreshold(im, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,31,2)\n",
    "\n",
    "    thre_img = cv2.fastNlMeansDenoising(thre_img, h=13, searchWindowSize=7)\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    thre_img = cv2.erode(thre_img, kernel, iterations = 1)\n",
    "\n",
    "    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 13))\n",
    "    dilate = cv2.dilate(thre_img, rect_kernel, iterations = 1)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        bound = cv2.resize(img, (50,50))\n",
    "        not_found += 1\n",
    "    else:\n",
    "        max_area = -1\n",
    "        bx, by, bw, bh = None, None, None, None\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            if w * h > max_area:\n",
    "                bx, by, bw, bh = x, y, w, h\n",
    "                max_area = w * h\n",
    "            # Drawing a rectangle on copied image\n",
    "        bound = cv2.resize(img[by:by+bh, bx:bx+bw], (50, 50))\n",
    "        rect = cv2.rectangle(ori_img, (bx, by), (bx + bw, by + bh), (0, 0, 255), 1)\n",
    "        found += 1\n",
    "    save_path = os.path.join(path, 'Modified', img_name)\n",
    "    cv2.imwrite(save_path, bound)\n",
    "    \n",
    "print('Total {} img found {} bounding box\\t {} not found\\t{} null images'.format(total, found, not_found, null_cnt))\n",
    "        #     plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "#     imgs = [thre_img, dilate, ori_img, bound]\n",
    "#     titles = ['thres', 'dilate', 'result', 'bounding']\n",
    "#     fig, axs = plt.subplots(nrows=1, ncols=4)\n",
    "#     for i, ax in enumerate(axs.flatten()):\n",
    "#         plt.sca(ax)\n",
    "#         if i != 2: plt.imshow(imgs[i], 'gray', vmin=0, vmax=255)\n",
    "#         else: plt.imshow(imgs[i])\n",
    "#         plt.title('Image: {}'.format(titles[i]))\n",
    "\n",
    "#     #plt.tight_layout()\n",
    "#     plt.show()\n",
    "#     input()\n",
    "\n",
    "# print('Total Image Cnt ', cnt)\n",
    "# print('Total Character ', len(store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImgDataset import ImgDataset\n",
    "\n",
    "dir_path = '/nfs/nas-5.1/wbcheng/Chinese_Word_Recognition'\n",
    "with open('./word2label.json', 'r', encoding='utf-8') as f:\n",
    "    word2label = json.load(f)\n",
    "    \n",
    "trainset = ImgDataset(dir_path, iword2label)\n",
    "loader = DataLoader(trainset, batch_size=4)\n",
    "\n",
    "# batchs = next(iter(loader))\n",
    "\n",
    "# plt.figure(figsize=(50,50))\n",
    "for batchs in loader:\n",
    "    for idx in range(len(batchs['image'])):\n",
    "        img = batchs['image'][idx]\n",
    "        label = batchs['word'][idx]\n",
    "        print(label)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.transpose(vutils.make_grid(img,nrow=2,padding=1,normalize=True).numpy(),(1,2,0)), cmap='gray')\n",
    "        plt.show() \n",
    "        input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./false_cases', 'rb') as f:\n",
    "    false_cases = np.load(f)\n",
    "    \n",
    "path = '/nfs/nas-5.1/wbcheng/Chinese_Word_Recognition'\n",
    "for c in false_cases:\n",
    "    file_id = c[0]\n",
    "    print(c[0], ': ', c[1], 'pred as ', c[2])\n",
    "    im = cv2.imread(os.path.join(path, file_id), 1)\t# load image as bgr\n",
    "    im = im[:,:,::-1] \t# transform image to rgb\n",
    "    print(im.shape)\n",
    "#     print(im.size)\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./true_cases', 'rb') as f:\n",
    "    true_cases = np.load(f)\n",
    "    \n",
    "path = '/nfs/nas-5.1/wbcheng/Chinese_Word_Recognition'\n",
    "for c in true_cases:\n",
    "    file_id = c[0]\n",
    "    print(c[0], ': ', c[1], 'pred as ', c[2])\n",
    "    im = cv2.imread(os.path.join(path, file_id), 1)\t# load image as bgr\n",
    "    im = im[:,:,::-1] \t# transform image to rgb\n",
    "    print(im.shape)\n",
    "#     print(im.size)\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    input()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
